{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKd5ZwKvgpBTEvRH0CQLeu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SydanJainen/4EU-DeepLearningCourse/blob/main/Assignments/AssignementVAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bTjkCCifVbGi"
      },
      "outputs": [],
      "source": [
        "from matplotlib import cm\n",
        "import torch; torch.manual_seed(0)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils\n",
        "import torch.distributions\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split\n",
        "import random\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dataset = datasets.MNIST('./data',\n",
        "                               train=True,\n",
        "                               download=True,\n",
        "                               transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                   ]))\n",
        "\n",
        "test_dataset = datasets.MNIST('./data',\n",
        "                                    train=False,\n",
        "                               transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                   ]))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                                batch_size=batch_size,\n",
        "                                                shuffle=False)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                                batch_size=batch_size,\n",
        "                                                shuffle=False)\n",
        "\n",
        "train_images = train_loader.dataset.data.detach().numpy().reshape(-1, 28*28)\n",
        "print(f'Num training images: {len(train_images)},\\tmin val: {train_images.min():.3f},\\tmax val: {train_images.max():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nidWUvwtYHde",
        "outputId": "84976119-23a9-407b-98d8-22aa5e9355db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 89850689.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 22731411.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 24573584.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 13588108.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Num training images: 60000,\tmin val: 0.000,\tmax val: 255.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPH5u6CtYMrq",
        "outputId": "9dcbc26d-b5aa-489e-c964-b57fcf8b41bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHXJkzKiVtDJ"
      },
      "source": [
        "Try to implement a **denoising autoencoder**; you can use the function below to generate noisy input samples with a gaussian noise.\n",
        "\n",
        "1. modifiy the function to allow adding salt 'n pepper noise to the images\n",
        "2. implement a DAE; you can use different numbers of layers / activation functions / dimension of latent space\n",
        "3. Make a plot with the original image, the noised image and the reconstructed image for several examples of input images.\n",
        "4. compare different types (gaussian / salt n pepper) and levels of noise on the performance of the DAE\n",
        "5. compare different DAE architectures regarding the denoising performances.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CiN_zPfWVtDJ"
      },
      "outputs": [],
      "source": [
        "train_images = train_loader.dataset.data.detach().numpy()\n",
        "test_images = test_loader.dataset.data.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GsqW_TGDVtDK"
      },
      "outputs": [],
      "source": [
        "def add_gaussian_noise(img,mean=10,var=30):\n",
        "    img=img.astype(np.float32)\n",
        "\n",
        "    sigma=var**.5\n",
        "    noise=np.random.normal(mean,sigma,img.shape)\n",
        "    img=img+noise\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_salt_and_pepper(img, width = 26, height = 26, percent = 10):\n",
        "    img=img.astype(np.float32)\n",
        "    for _ in range(int(width* height * percent / 100)):\n",
        "      x = random.randint(0,width)\n",
        "      y = random.randint(0,height)\n",
        "      if img[x][y] > 126:\n",
        "          img[x][y] = 0\n",
        "      else:\n",
        "        img[x][y] = 255\n",
        "    return img"
      ],
      "metadata": {
        "id": "Kic3hRPuYYji"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2FtYH1LaVtDK"
      },
      "outputs": [],
      "source": [
        "noised_train = np.zeros((len(train_images),28,28),dtype='float32')\n",
        "for i in range(len(train_images)):\n",
        "  noised_train[i]=add_gaussian_noise(train_images[i]).reshape(28,28)\n",
        "  noised_train[i] = np.float32(noised_train[i])\n",
        "\n",
        "noised_test = np.zeros((len(test_images),28,28),dtype='float32')\n",
        "for i in range(len(test_images)):\n",
        "  noised_test[i]=add_gaussian_noise(test_images[i]).reshape(28,28)\n",
        "  noised_test[i] = np.float32(noised_test[i])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images( original, noised, denoised):\n",
        "  plt.figure(figsize=(16, 3))\n",
        "  plt.subplot(121)\n",
        "  plt.imshow(original, cmap='gray')\n",
        "  plt.title('Original Image')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(122)\n",
        "  plt.imshow(noised, cmap='gray')\n",
        "  plt.title('Reconstructed Image')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(123)\n",
        "  plt.imshow(denoised, cmap='gray')\n",
        "  plt.title('Reconstructed Image')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "_DnWAMwLZyVH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9ewKXHNOVtDL"
      },
      "outputs": [],
      "source": [
        "class noisedDataset():\n",
        "\n",
        "  def __init__(self,datasetnoised,datasetclean,transform):\n",
        "    self.noise=datasetnoised\n",
        "    self.clean=datasetclean\n",
        "    #self.labels=labels\n",
        "    self.transform=transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.noise)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    xNoise=self.noise[idx]\n",
        "    xClean=self.clean[idx]\n",
        "    #y=self.labels[idx]\n",
        "\n",
        "    if self.transform != None:\n",
        "      xNoise=self.transform(xNoise)\n",
        "      xClean=self.transform(xClean)\n",
        "\n",
        "\n",
        "    return (xNoise,xClean)\n",
        "\n",
        "\n",
        "tsfms=transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "data = noisedDataset(noised_train,train_images,tsfms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FtBSMERo2S0u"
      },
      "outputs": [],
      "source": [
        "class VariationalEncoder(nn.Module):\n",
        "    def __init__(self, latent_dims,input_dim):\n",
        "        super(VariationalEncoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_dim**2, 512)\n",
        "        self.linear2 = nn.Linear(512, latent_dims)\n",
        "        self.linear3 = nn.Linear(512, latent_dims)\n",
        "\n",
        "        self.N = torch.distributions.Normal(0, 1)\n",
        "        self.N.loc = self.N.loc.to(device)\n",
        "        self.N.scale = self.N.scale.to(device)\n",
        "        self.kl = 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        sigma = torch.exp(self.linear3(x))\n",
        "        mu =  self.linear2(x)\n",
        "        z = mu + sigma*self.N.sample(mu.shape)\n",
        "        self.kl = (0.5*sigma**2 + 0.5*mu**2 - torch.log(sigma) - 1/2).sum()\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iow-o15M2S0q"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dims,input_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(latent_dims, 512)\n",
        "        self.linear2 = nn.Linear(512, input_dim**2)\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = F.relu(self.linear1(z))\n",
        "        z = torch.sigmoid(self.linear2(z))\n",
        "        return z.reshape((-1, 1, input_dim, input_dim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Si1LfPiQ2S0u"
      },
      "outputs": [],
      "source": [
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(self, latent_dims,ipnut_dim):\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        self.encoder = VariationalEncoder(latent_dims,input_dim)\n",
        "        self.decoder = Decoder(latent_dims,input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        return self.decoder(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "iDFRvbht2S0v"
      },
      "outputs": [],
      "source": [
        "def train(autoencoder, data, epochs=20,l=5):\n",
        "    opt = torch.optim.Adam(autoencoder.parameters())\n",
        "    losses_recon = np.array([])\n",
        "    losses_kl = np.array([])\n",
        "    for epoch in range(epochs):\n",
        "        print(\"epoch: \",epoch)\n",
        "        loss_recon_e=0\n",
        "        loss_kl_e=0\n",
        "        for x, y in data:\n",
        "            x = x.to(device) # GPU\n",
        "            opt.zero_grad()\n",
        "            x_hat = autoencoder(x)\n",
        "            loss_recon = ((x - x_hat)**2).sum()\n",
        "            loss_kl = autoencoder.encoder.kl\n",
        "            loss = loss_recon + l*loss_kl\n",
        "            loss.backward()\n",
        "            loss_recon_e += loss_recon.to('cpu').detach().numpy()\n",
        "            loss_kl_e += loss_kl.to('cpu').detach().numpy()\n",
        "            opt.step()\n",
        "        losses_recon = np.append(losses_recon,loss_recon_e)\n",
        "        losses_kl = np.append(losses_kl,loss_kl_e)\n",
        "    return autoencoder, losses_recon,losses_kl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "G2MbLLBLVtDF"
      },
      "outputs": [],
      "source": [
        "data = torch.utils.data.DataLoader(\n",
        "        torchvision.datasets.MNIST('./data',\n",
        "               transform=torchvision.transforms.ToTensor(),\n",
        "               download=True),\n",
        "        batch_size=128,\n",
        "        shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#noise the dataset\n",
        "sp_train = np.zeros((len(train_images),28,28),dtype='float32')\n",
        "for i in range(len(train_images)):\n",
        "  sp_train[i]=add_salt_and_pepper(train_images[i]).reshape(28,28)\n",
        "  sp_train[i] = np.float32(sp_train[i])\n",
        "\n",
        "sp_test = np.zeros((len(test_images),28,28),dtype='float32')\n",
        "for i in range(len(test_images)):\n",
        "  sp_test[i]=add_salt_and_pepper(test_images[i]).reshape(28,28)\n",
        "  sp_test[i] = np.float32(noised_test[i])"
      ],
      "metadata": {
        "id": "PdMf2nj7j-HQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images()"
      ],
      "metadata": {
        "id": "RRXls3Mplk9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee_2aVGK2S0v"
      },
      "outputs": [],
      "source": [
        "latent_dims = 2\n",
        "input_dim=28\n",
        "vae = VariationalAutoencoder(latent_dims,input_dim).to(device) # GPU\n",
        "vae,loss_recon,loss_kl = train(vae, data,epochs=40,l=1)"
      ]
    }
  ]
}