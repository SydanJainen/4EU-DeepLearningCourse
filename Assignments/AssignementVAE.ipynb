{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyf2A1jYl+b2kSoDd4Otx5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SydanJainen/4EU-DeepLearningCourse/blob/main/Assignments/AssignementVAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTjkCCifVbGi"
      },
      "outputs": [],
      "source": [
        "from matplotlib import cm\n",
        "import torch; torch.manual_seed(0)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils\n",
        "import torch.distributions\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dataset = datasets.MNIST('./data',\n",
        "                               train=True,\n",
        "                               download=True,\n",
        "                               transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                   ]))\n",
        "\n",
        "test_dataset = datasets.MNIST('./data',\n",
        "                                    train=False,\n",
        "                               transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                   ]))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                                batch_size=batch_size,\n",
        "                                                shuffle=False)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                                batch_size=batch_size,\n",
        "                                                shuffle=False)\n",
        "\n",
        "train_images = train_loader.dataset.data.detach().numpy().reshape(-1, 28*28)\n",
        "print(f'Num training images: {len(train_images)},\\tmin val: {train_images.min():.3f},\\tmax val: {train_images.max():.3f}')"
      ],
      "metadata": {
        "id": "nidWUvwtYHde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "id": "EPH5u6CtYMrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHXJkzKiVtDJ"
      },
      "source": [
        "Try to implement a **denoising autoencoder**; you can use the function below to generate noisy input samples with a gaussian noise.\n",
        "\n",
        "1. modifiy the function to allow adding salt 'n pepper noise to the images\n",
        "2. implement a DAE; you can use different numbers of layers / activation functions / dimension of latent space\n",
        "3. Make a plot with the original image, the noised image and the reconstructed image for several examples of input images.\n",
        "4. compare different types (gaussian / salt n pepper) and levels of noise on the performance of the DAE\n",
        "5. compare different DAE architectures regarding the denoising performances.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiN_zPfWVtDJ"
      },
      "outputs": [],
      "source": [
        "train_images = train_loader.dataset.data.detach().numpy()\n",
        "test_images = test_loader.dataset.data.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsqW_TGDVtDK"
      },
      "outputs": [],
      "source": [
        "def add_gaussian_noise(img,mean=10,var=30):\n",
        "    import math\n",
        "    img=img.astype(np.float32)\n",
        "\n",
        "    sigma=var**.5\n",
        "    noise=np.random.normal(mean,sigma,img.shape)\n",
        "    img=img+noise\n",
        "    return img\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FtYH1LaVtDK"
      },
      "outputs": [],
      "source": [
        "noised_train = np.zeros((len(train_images),28,28),dtype='float32')\n",
        "for i in range(len(train_images)):\n",
        "  noised_train[i]=add_gaussian_noise(train_images[i]).reshape(28,28)\n",
        "  noised_train[i] = np.float32(noised_train[i])\n",
        "\n",
        "noised_test = np.zeros((len(test_images),28,28),dtype='float32')\n",
        "for i in range(len(test_images)):\n",
        "  noised_test[i]=add_gaussian_noise(test_images[i]).reshape(28,28)\n",
        "  noised_test[i] = np.float32(noised_test[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ewKXHNOVtDL"
      },
      "outputs": [],
      "source": [
        "class noisedDataset():\n",
        "\n",
        "  def __init__(self,datasetnoised,datasetclean,transform):\n",
        "    self.noise=datasetnoised\n",
        "    self.clean=datasetclean\n",
        "    #self.labels=labels\n",
        "    self.transform=transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.noise)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    xNoise=self.noise[idx]\n",
        "    xClean=self.clean[idx]\n",
        "    #y=self.labels[idx]\n",
        "\n",
        "    if self.transform != None:\n",
        "      xNoise=self.transform(xNoise)\n",
        "      xClean=self.transform(xClean)\n",
        "\n",
        "\n",
        "    return (xNoise,xClean)\n",
        "\n",
        "\n",
        "tsfms=transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "data = noisedDataset(noised_train,train_images,tsfms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtBSMERo2S0u"
      },
      "outputs": [],
      "source": [
        "class VariationalEncoder(nn.Module):\n",
        "    def __init__(self, latent_dims,input_dim):\n",
        "        super(VariationalEncoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_dim**2, 512)\n",
        "        self.linear2 = nn.Linear(512, latent_dims)\n",
        "        self.linear3 = nn.Linear(512, latent_dims)\n",
        "\n",
        "        self.N = torch.distributions.Normal(0, 1)\n",
        "        self.N.loc = self.N.loc.to(device)\n",
        "        self.N.scale = self.N.scale.to(device)\n",
        "        self.kl = 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        sigma = torch.exp(self.linear3(x))\n",
        "        mu =  self.linear2(x)\n",
        "        z = mu + sigma*self.N.sample(mu.shape)\n",
        "        self.kl = (0.5*sigma**2 + 0.5*mu**2 - torch.log(sigma) - 1/2).sum()\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iow-o15M2S0q"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dims,input_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(latent_dims, 512)\n",
        "        self.linear2 = nn.Linear(512, input_dim**2)\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = F.relu(self.linear1(z))\n",
        "        z = torch.sigmoid(self.linear2(z))\n",
        "        return z.reshape((-1, 1, input_dim, input_dim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Si1LfPiQ2S0u"
      },
      "outputs": [],
      "source": [
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(self, latent_dims,ipnut_dim):\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        self.encoder = VariationalEncoder(latent_dims,input_dim)\n",
        "        self.decoder = Decoder(latent_dims,input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        return self.decoder(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDFRvbht2S0v"
      },
      "outputs": [],
      "source": [
        "def train(autoencoder, data, epochs=20,l=5):\n",
        "    opt = torch.optim.Adam(autoencoder.parameters())\n",
        "    losses_recon = np.array([])\n",
        "    losses_kl = np.array([])\n",
        "    for epoch in range(epochs):\n",
        "        print(\"epoch: \",epoch)\n",
        "        loss_recon_e=0\n",
        "        loss_kl_e=0\n",
        "        for x, y in data:\n",
        "            x = x.to(device) # GPU\n",
        "            opt.zero_grad()\n",
        "            x_hat = autoencoder(x)\n",
        "            loss_recon = ((x - x_hat)**2).sum()\n",
        "            loss_kl = autoencoder.encoder.kl\n",
        "            loss = loss_recon + l*loss_kl\n",
        "            loss.backward()\n",
        "            loss_recon_e += loss_recon.to('cpu').detach().numpy()\n",
        "            loss_kl_e += loss_kl.to('cpu').detach().numpy()\n",
        "            opt.step()\n",
        "        losses_recon = np.append(losses_recon,loss_recon_e)\n",
        "        losses_kl = np.append(losses_kl,loss_kl_e)\n",
        "    return autoencoder, losses_recon,losses_kl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2MbLLBLVtDF"
      },
      "outputs": [],
      "source": [
        "data = torch.utils.data.DataLoader(\n",
        "        torchvision.datasets.MNIST('./data',\n",
        "               transform=torchvision.transforms.ToTensor(),\n",
        "               download=True),\n",
        "        batch_size=128,\n",
        "        shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee_2aVGK2S0v",
        "outputId": "31610dc0-1822-48e4-93f4-9257e83ff8be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch:  0\n",
            "epoch:  1\n",
            "epoch:  2\n",
            "epoch:  3\n",
            "epoch:  4\n",
            "epoch:  5\n",
            "epoch:  6\n",
            "epoch:  7\n",
            "epoch:  8\n",
            "epoch:  9\n",
            "epoch:  10\n",
            "epoch:  11\n",
            "epoch:  12\n",
            "epoch:  13\n",
            "epoch:  14\n",
            "epoch:  15\n",
            "epoch:  16\n",
            "epoch:  17\n",
            "epoch:  18\n",
            "epoch:  19\n",
            "epoch:  20\n",
            "epoch:  21\n",
            "epoch:  22\n",
            "epoch:  23\n",
            "epoch:  24\n",
            "epoch:  25\n",
            "epoch:  26\n",
            "epoch:  27\n",
            "epoch:  28\n",
            "epoch:  29\n",
            "epoch:  30\n",
            "epoch:  31\n",
            "epoch:  32\n",
            "epoch:  33\n",
            "epoch:  34\n",
            "epoch:  35\n",
            "epoch:  36\n",
            "epoch:  37\n",
            "epoch:  38\n",
            "epoch:  39\n"
          ]
        }
      ],
      "source": [
        "latent_dims = 2\n",
        "input_dim=28\n",
        "vae = VariationalAutoencoder(latent_dims,input_dim).to(device) # GPU\n",
        "vae,loss_recon,loss_kl = train(vae, data,epochs=40,l=1)"
      ]
    }
  ]
}